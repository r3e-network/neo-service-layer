using Microsoft.Extensions.Logging;
using Moq;
using System.Text;
using System.Text.Json;
using Xunit;
using System.IO.Compression;
using System.Security.Cryptography;
using System.Collections.Generic;
using System.Diagnostics.CodeAnalysis;
using System.Linq;
using System.Threading.Tasks;
using System.Threading;
using System;


namespace NeoServiceLayer.Services.Tee.Tests
{
    /// <summary>
    /// Comprehensive unit tests for SGX Enclave StorageService
    /// Tests secure storage, encryption, compression, and data integrity features
    /// </summary>
    public class StorageServiceTests : IDisposable
    {
        private readonly Mock<ILogger<StorageService>> _mockLogger;
        private readonly StorageService _storageService;
        private readonly EnclaveConfig _testConfig;
        private readonly string _testStoragePath;

        public StorageServiceTests()
        {
            _mockLogger = new Mock<ILogger<StorageService>>();
            _testStoragePath = Path.Combine(Path.GetTempPath(), $"sgx_storage_test_{Guid.NewGuid()}");
            
            _testConfig = new EnclaveConfig
            {
                storage_path = _testStoragePath
            };
            
            _storageService = StorageService.NewAsync(_testConfig).Result;
        }

        #region Basic Storage Operations Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreData_ValidData_ShouldSucceed()
        {
            // Arrange
            var key = "test_store_key";
            var data = Encoding.UTF8.GetBytes("Hello, SGX Storage!");
            var encryptionKey = "test_encryption_key";

            // Act
            var result = await _storageService.StoreDataAsync(key, data, encryptionKey, compress: false);

            // Assert
            Assert.NotNull(result);
            var metadata = JsonSerializer.Deserialize<StorageMetadata>(result);
            Assert.Equal(key, metadata.Key);
            Assert.Equal(data.Length, metadata.Size);
            Assert.True(metadata.Encryption);
            Assert.False(metadata.CompressedSize.HasValue); // No compression
            Assert.True(metadata.CreatedAt > 0);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreRetrieve_RoundTrip_ShouldPreserveData()
        {
            // Arrange
            var key = "test_roundtrip_key";
            var originalData = Encoding.UTF8.GetBytes("Round trip test data with special chars: Ã¥Ã¤Ã¶ ðŸ”’");
            var encryptionKey = "test_encryption_key_roundtrip";

            // Act
            await _storageService.StoreDataAsync(key, originalData, encryptionKey, compress: true);
            var retrievedData = await _storageService.RetrieveDataAsync(key, encryptionKey);

            // Assert
            Assert.Equal(originalData, retrievedData);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task RetrieveData_NonExistentKey_ShouldThrow()
        {
            // Act & Assert
            await Assert.ThrowsAsync<KeyNotFoundException>(
                () => _storageService.RetrieveDataAsync("nonexistent_key", "any_key")
            );
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task DeleteData_ExistingKey_ShouldRemoveData()
        {
            // Arrange
            var key = "test_delete_key";
            var data = Encoding.UTF8.GetBytes("Data to delete");
            var encryptionKey = "delete_test_key";

            await _storageService.StoreDataAsync(key, data, encryptionKey, false);

            // Act
            var deleteResult = await _storageService.DeleteDataAsync(key);

            // Assert
            Assert.NotNull(deleteResult);
            var result = JsonSerializer.Deserialize<JsonElement>(deleteResult);
            Assert.True(result.GetProperty("deleted").GetBoolean());
            Assert.Equal(key, result.GetProperty("key").GetString());

            // Verify data is actually deleted
            await Assert.ThrowsAsync<KeyNotFoundException>(
                () => _storageService.RetrieveDataAsync(key, encryptionKey)
            );
        }

        [Theory]
        [InlineData("")]
        [InlineData(null)]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreData_InvalidKey_ShouldThrow(string key)
        {
            // Arrange
            var data = Encoding.UTF8.GetBytes("Test data");
            var encryptionKey = "test_key";

            // Act & Assert
            await Assert.ThrowsAsync<ArgumentException>(
                () => _storageService.StoreDataAsync(key, data, encryptionKey, false)
            );
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreData_DuplicateKey_ShouldThrow()
        {
            // Arrange
            var key = "duplicate_key_test";
            var data = Encoding.UTF8.GetBytes("First data");
            var encryptionKey = "test_key";

            await _storageService.StoreDataAsync(key, data, encryptionKey, false);

            // Act & Assert
            await Assert.ThrowsAsync<InvalidOperationException>(
                () => _storageService.StoreDataAsync(key, data, encryptionKey, false)
            );
        }

        #endregion

        #region Compression Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreData_WithCompression_ShouldReduceSize()
        {
            // Arrange - Create highly compressible data
            var key = "test_compression_key";
            var compressibleData = Encoding.UTF8.GetBytes(new string('A', 10000)); // 10KB of 'A's
            var encryptionKey = "compression_test_key";

            // Act
            var result = await _storageService.StoreDataAsync(key, compressibleData, encryptionKey, compress: true);

            // Assert
            var metadata = JsonSerializer.Deserialize<StorageMetadata>(result);
            Assert.True(metadata.CompressedSize.HasValue);
            Assert.True(metadata.CompressedSize < metadata.Size, 
                $"Compressed size {metadata.CompressedSize} should be less than original size {metadata.Size}");

            // Verify data integrity after compression
            var retrievedData = await _storageService.RetrieveDataAsync(key, encryptionKey);
            Assert.Equal(compressibleData, retrievedData);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreData_CompressionFallback_ShouldNotCompressRandomData()
        {
            // Arrange - Random data doesn't compress well
            var key = "test_random_data_key";
            var randomData = new byte[1024];
            new Random(42).NextBytes(randomData);
            var encryptionKey = "random_data_test_key";

            // Act
            var result = await _storageService.StoreDataAsync(key, randomData, encryptionKey, compress: true);

            // Assert
            var metadata = JsonSerializer.Deserialize<StorageMetadata>(result);
            // For random data, compression might not provide benefits, so it should fall back to no compression
            var retrievedData = await _storageService.RetrieveDataAsync(key, encryptionKey);
            Assert.Equal(randomData, retrievedData);
        }

        [Theory]
        [InlineData(true)]
        [InlineData(false)]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreRetrieve_DifferentCompressionSettings_ShouldWork(bool useCompression)
        {
            // Arrange
            var key = $"test_compression_{useCompression}";
            var testData = Encoding.UTF8.GetBytes("Test data for compression setting: " + useCompression);
            var encryptionKey = "compression_setting_test";

            // Act
            await _storageService.StoreDataAsync(key, testData, encryptionKey, useCompression);
            var retrievedData = await _storageService.RetrieveDataAsync(key, encryptionKey);

            // Assert
            Assert.Equal(testData, retrievedData);
        }

        #endregion

        #region Encryption and Security Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task RetrieveData_WrongEncryptionKey_ShouldThrow()
        {
            // Arrange
            var key = "test_wrong_key";
            var data = Encoding.UTF8.GetBytes("Sensitive data");
            var correctKey = "correct_encryption_key";
            var wrongKey = "wrong_encryption_key";

            await _storageService.StoreDataAsync(key, data, correctKey, false);

            // Act & Assert
            await Assert.ThrowsAsync<CryptographicException>(
                () => _storageService.RetrieveDataAsync(key, wrongKey)
            );
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoredData_ShouldBeEncrypted()
        {
            // Arrange
            var key = "test_encryption_verification";
            var sensitiveData = Encoding.UTF8.GetBytes("This is very sensitive information!");
            var encryptionKey = "encryption_verification_key";

            // Act
            await _storageService.StoreDataAsync(key, sensitiveData, encryptionKey, false);

            // Assert - Check that raw file content doesn't contain original data
            var storedFileContent = await GetRawStoredFileContentAsync(key);
            Assert.NotNull(storedFileContent);
            Assert.True(storedFileContent.Length > 0);
            
            // The raw content should not contain the original sensitive data
            var storedText = Encoding.UTF8.GetString(storedFileContent);
            Assert.DoesNotContain("This is very sensitive information!", storedText);

            // But decryption should work
            var decryptedData = await _storageService.RetrieveDataAsync(key, encryptionKey);
            Assert.Equal(sensitiveData, decryptedData);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task DataIntegrity_TamperedData_ShouldDetectCorruption()
        {
            // Arrange
            var key = "test_integrity_check";
            var data = Encoding.UTF8.GetBytes("Data with integrity protection");
            var encryptionKey = "integrity_test_key";

            await _storageService.StoreDataAsync(key, data, encryptionKey, false);

            // Act - Tamper with stored data
            await TamperWithStoredFileAsync(key);

            // Assert - Should detect tampering
            await Assert.ThrowsAsync<InvalidDataException>(
                () => _storageService.RetrieveDataAsync(key, encryptionKey)
            );
        }

        #endregion

        #region Metadata Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task GetMetadata_ExistingKey_ShouldReturnCorrectInfo()
        {
            // Arrange
            var key = "test_metadata_key";
            var data = Encoding.UTF8.GetBytes("Test data for metadata");
            var encryptionKey = "metadata_test_key";
            var beforeStore = DateTimeOffset.UtcNow.ToUnixTimeSeconds();

            await _storageService.StoreDataAsync(key, data, encryptionKey, compress: true);

            // Act
            var metadataJson = await _storageService.GetMetadataAsync(key);

            // Assert
            Assert.NotNull(metadataJson);
            var metadata = JsonSerializer.Deserialize<StorageMetadata>(metadataJson);
            
            Assert.Equal(key, metadata.Key);
            Assert.Equal(data.Length, metadata.Size);
            Assert.True(metadata.Encryption);
            Assert.True(metadata.CreatedAt >= beforeStore);
            Assert.True(metadata.AccessedAt >= beforeStore);
            Assert.NotEmpty(metadata.Hash);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task GetMetadata_NonExistentKey_ShouldThrow()
        {
            // Act & Assert
            await Assert.ThrowsAsync<KeyNotFoundException>(
                () => _storageService.GetMetadataAsync("nonexistent_metadata_key")
            );
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task RetrieveData_ShouldUpdateAccessMetadata()
        {
            // Arrange
            var key = "test_access_tracking";
            var data = Encoding.UTF8.GetBytes("Access tracking test data");
            var encryptionKey = "access_tracking_key";

            await _storageService.StoreDataAsync(key, data, encryptionKey, false);
            var initialMetadata = JsonSerializer.Deserialize<StorageMetadata>(
                await _storageService.GetMetadataAsync(key)
            );

            // Wait a moment to ensure timestamp difference
            await Task.Delay(1100);

            // Act
            await _storageService.RetrieveDataAsync(key, encryptionKey);
            var updatedMetadata = JsonSerializer.Deserialize<StorageMetadata>(
                await _storageService.GetMetadataAsync(key)
            );

            // Assert
            Assert.True(updatedMetadata.AccessedAt > initialMetadata.AccessedAt);
            Assert.Equal(initialMetadata.AccessCount + 1, updatedMetadata.AccessCount);
        }

        #endregion

        #region Key Listing Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task ListKeys_ShouldReturnAllStoredKeys()
        {
            // Arrange
            var keys = new[] { "list_key_1", "list_key_2", "list_key_3" };
            var data = Encoding.UTF8.GetBytes("List test data");
            var encryptionKey = "list_test_key";

            foreach (var key in keys)
            {
                await _storageService.StoreDataAsync(key, data, encryptionKey, false);
            }

            // Act
            var keysResult = await _storageService.ListKeysAsync();

            // Assert
            Assert.NotNull(keysResult);
            var keysList = JsonSerializer.Deserialize<JsonElement>(keysResult);
            var returnedKeys = keysList.GetProperty("keys").EnumerateArray()
                .Select(k => k.GetString()).ToArray();

            foreach (var key in keys)
            {
                Assert.Contains(key, returnedKeys);
            }
            
            Assert.Equal(keys.Length, keysList.GetProperty("count").GetInt32());
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task ListKeys_EmptyStorage_ShouldReturnEmptyList()
        {
            // Act
            var keysResult = await _storageService.ListKeysAsync();

            // Assert
            var keysList = JsonSerializer.Deserialize<JsonElement>(keysResult);
            Assert.Equal(0, keysList.GetProperty("count").GetInt32());
        }

        #endregion

        #region Storage Usage and Statistics Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task GetUsageStats_ShouldReturnAccurateStatistics()
        {
            // Arrange
            var testData = new[]
            {
                (key: "stats_key_1", data: new byte[1024], compress: false),
                (key: "stats_key_2", data: new byte[2048], compress: true),
                (key: "stats_key_3", data: new byte[512], compress: false)
            };

            foreach (var (key, data, compress) in testData)
            {
                new Random(42).NextBytes(data);
                await _storageService.StoreDataAsync(key, data, "stats_test_key", compress);
            }

            // Act
            var statsResult = await _storageService.GetUsageStatsAsync();

            // Assert
            Assert.NotNull(statsResult);
            var stats = JsonSerializer.Deserialize<StorageStats>(statsResult);
            
            Assert.Equal(testData.Length, stats.TotalFiles);
            Assert.Equal(testData.Sum(t => t.data.Length), (int)stats.TotalSize);
            Assert.True(stats.TotalCompressedSize > 0);
            Assert.True(stats.CompressionRatio > 0);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task OptimizeStorage_ShouldRunWithoutErrors()
        {
            // Arrange - Create some test data
            var testKeys = new[] { "opt_key_1", "opt_key_2", "opt_key_3" };
            var data = Encoding.UTF8.GetBytes("Optimization test data");
            
            foreach (var key in testKeys)
            {
                await _storageService.StoreDataAsync(key, data, "opt_test_key", false);
            }

            // Act
            var optimizationResult = await _storageService.OptimizeStorageAsync();

            // Assert
            Assert.NotNull(optimizationResult);
            var result = JsonSerializer.Deserialize<StorageOptimizationResults>(optimizationResult);
            Assert.True(result.OptimizationTimeMs >= 0);
        }

        #endregion

        #region Performance and Large Data Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        [Trait("Performance", "True")]
        public async Task StoreRetrieve_LargeData_ShouldWork()
        {
            // Arrange
            var key = "large_data_test";
            var largeData = new byte[1024 * 1024]; // 1MB
            new Random(42).NextBytes(largeData);
            var encryptionKey = "large_data_key";

            // Act
            var stopwatch = System.Diagnostics.Stopwatch.StartNew();
            await _storageService.StoreDataAsync(key, largeData, encryptionKey, compress: true);
            var storeTime = stopwatch.ElapsedMilliseconds;

            stopwatch.Restart();
            var retrievedData = await _storageService.RetrieveDataAsync(key, encryptionKey);
            var retrieveTime = stopwatch.ElapsedMilliseconds;

            // Assert
            Assert.Equal(largeData, retrievedData);
            Assert.True(storeTime < 5000, $"Store operation took {storeTime}ms, should be under 5 seconds");
            Assert.True(retrieveTime < 3000, $"Retrieve operation took {retrieveTime}ms, should be under 3 seconds");
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreData_ExceedsSizeLimit_ShouldThrow()
        {
            // Arrange
            var key = "too_large_key";
            var tooLargeData = new byte[101 * 1024 * 1024]; // Slightly over 100MB limit
            var encryptionKey = "size_limit_test";

            // Act & Assert
            await Assert.ThrowsAsync<ArgumentException>(
                () => _storageService.StoreDataAsync(key, tooLargeData, encryptionKey, false)
            );
        }

        #endregion

        #region Concurrent Access Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task ConcurrentOperations_ShouldNotInterfere()
        {
            // Arrange
            var tasks = new List<Task>();
            var keyPrefix = "concurrent_test";
            var testData = Encoding.UTF8.GetBytes("Concurrent test data");
            var encryptionKey = "concurrent_key";

            // Act - Create multiple concurrent storage operations
            for (int i = 0; i < 20; i++)
            {
                var taskId = i;
                tasks.Add(Task.Run(async () =>
                {
                    var key = $"{keyPrefix}_{taskId}";
                    await _storageService.StoreDataAsync(key, testData, encryptionKey, true);
                    var retrieved = await _storageService.RetrieveDataAsync(key, encryptionKey);
                    Assert.Equal(testData, retrieved);
                    await _storageService.DeleteDataAsync(key);
                }));
            }

            // Assert
            await Task.WhenAll(tasks);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task ReadWriteContention_ShouldHandleGracefully()
        {
            // Arrange
            var key = "contention_test_key";
            var data = Encoding.UTF8.GetBytes("Contention test data");
            var encryptionKey = "contention_key";

            await _storageService.StoreDataAsync(key, data, encryptionKey, false);

            var readTasks = new List<Task<byte[]>>();
            
            // Act - Multiple concurrent reads
            for (int i = 0; i < 50; i++)
            {
                readTasks.Add(_storageService.RetrieveDataAsync(key, encryptionKey));
            }

            var results = await Task.WhenAll(readTasks);

            // Assert - All reads should return the same data
            foreach (var result in results)
            {
                Assert.Equal(data, result);
            }
        }

        #endregion

        #region Edge Cases and Error Handling Tests

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreRetrieve_EmptyData_ShouldWork()
        {
            // Arrange
            var key = "empty_data_test";
            var emptyData = Array.Empty<byte>();
            var encryptionKey = "empty_data_key";

            // Act
            await _storageService.StoreDataAsync(key, emptyData, encryptionKey, false);
            var retrieved = await _storageService.RetrieveDataAsync(key, encryptionKey);

            // Assert
            Assert.Equal(emptyData, retrieved);
        }

        [Fact]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreRetrieve_BinaryData_ShouldPreserveBytes()
        {
            // Arrange
            var key = "binary_data_test";
            var binaryData = new byte[] { 0x00, 0xFF, 0xAA, 0x55, 0x01, 0xFE, 0x02, 0xFD };
            var encryptionKey = "binary_data_key";

            // Act
            await _storageService.StoreDataAsync(key, binaryData, encryptionKey, true);
            var retrieved = await _storageService.RetrieveDataAsync(key, encryptionKey);

            // Assert
            Assert.Equal(binaryData, retrieved);
        }

        [Theory]
        [InlineData("key_with_spaces")]
        [InlineData("key-with-dashes")]
        [InlineData("key_with_underscores")]
        [InlineData("KeyWithCamelCase")]
        [InlineData("key123with456numbers")]
        [Trait("Category", "Unit")]
        [Trait("Component", "Storage")]
        public async Task StoreRetrieve_VariousKeyFormats_ShouldWork(string key)
        {
            // Arrange
            var data = Encoding.UTF8.GetBytes($"Data for key: {key}");
            var encryptionKey = "format_test_key";

            // Act
            await _storageService.StoreDataAsync(key, data, encryptionKey, false);
            var retrieved = await _storageService.RetrieveDataAsync(key, encryptionKey);

            // Assert
            Assert.Equal(data, retrieved);
        }

        #endregion

        #region Helper Methods

        private async Task<byte[]> GetRawStoredFileContentAsync(string key)
        {
            // This would access the actual stored file to verify encryption
            // For testing purposes, we'll simulate this
            var hash = System.Security.Cryptography.SHA256.HashData(Encoding.UTF8.GetBytes(key));
            var filename = Convert.ToHexString(hash).ToLowerInvariant() + ".dat";
            var filepath = Path.Combine(_testStoragePath, filename);
            
            if (File.Exists(filepath))
            {
                return await File.ReadAllBytesAsync(filepath);
            }
            
            return null;
        }

        private async Task TamperWithStoredFileAsync(string key)
        {
            // Simulate tampering with stored data
            var hash = System.Security.Cryptography.SHA256.HashData(Encoding.UTF8.GetBytes(key));
            var filename = Convert.ToHexString(hash).ToLowerInvariant() + ".dat";
            var filepath = Path.Combine(_testStoragePath, filename);
            
            if (File.Exists(filepath))
            {
                var content = await File.ReadAllBytesAsync(filepath);
                if (content.Length > 10)
                {
                    content[content.Length - 5] ^= 0xFF; // Flip some bits
                    await File.WriteAllBytesAsync(filepath, content);
                }
            }
        }

        #endregion

        public void Dispose()
        {
            _storageService?.Dispose();
            if (Directory.Exists(_testStoragePath))
            {
                Directory.Delete(_testStoragePath, recursive: true);
            }
        }
    }

    /// <summary>
    /// Mock/test implementation of StorageService for unit testing
    /// This simulates the actual SGX enclave storage behavior
    /// </summary>
    public class StorageService : IDisposable
    {
        private readonly Dictionary<string, StorageMetadata> _metadata = new();
        private readonly Dictionary<string, byte[]> _storage = new();
        private readonly EnclaveConfig _config;
        private readonly byte[] _masterKey;

        private StorageService(EnclaveConfig config)
        {
            _config = config;
            _masterKey = new byte[32];
            RandomNumberGenerator.Fill(_masterKey);
            
            // Create storage directory if it doesn't exist
            if (!Directory.Exists(config.storage_path))
            {
                Directory.CreateDirectory(config.storage_path);
            }
        }

        public static async Task<StorageService> NewAsync(EnclaveConfig config)
        {
            return await Task.FromResult(new StorageService(config));
        }

        public async Task<string> StoreDataAsync(string key, byte[] data, string encryptionKey, bool compress)
        {
            if (string.IsNullOrEmpty(key))
                throw new ArgumentException("Storage key cannot be empty");

            if (data.Length > 100 * 1024 * 1024) // 100MB limit
                throw new ArgumentException("Data size exceeds maximum file size limit");

            if (_metadata.ContainsKey(key))
                throw new InvalidOperationException($"Key '{key}' already exists");

            var now = DateTimeOffset.UtcNow.ToUnixTimeSeconds();
            
            // Process data (compression + encryption)
            var processedData = data;
            CompressionType? compressionType = null;
            
            if (compress)
            {
                var compressed = CompressData(data);
                if (compressed.Length < data.Length)
                {
                    processedData = compressed;
                    compressionType = CompressionType.Lz4;
                }
            }

            // Encrypt data
            var encryptedData = EncryptData(processedData, encryptionKey);
            
            // Calculate hash of original data
            var hash = Convert.ToHexString(SHA256.HashData(data)).ToLowerInvariant();
            
            // Store encrypted data
            _storage[key] = encryptedData;
            
            // Create and store metadata
            var metadata = new StorageMetadata
            {
                Key = key,
                Size = data.Length,
                CompressedSize = compressionType.HasValue ? processedData.Length : null,
                CreatedAt = now,
                AccessedAt = now,
                ModifiedAt = now,
                Compression = compressionType,
                Encryption = true,
                Hash = hash,
                AccessCount = 0
            };

            _metadata[key] = metadata;

            // Write to disk for verification tests
            await WriteToDiskAsync(key, encryptedData);

            return JsonSerializer.Serialize(metadata);
        }

        public async Task<byte[]> RetrieveDataAsync(string key, string encryptionKey)
        {
            if (string.IsNullOrEmpty(key))
                throw new ArgumentException("Storage key cannot be empty");

            if (!_metadata.TryGetValue(key, out var metadata))
                throw new KeyNotFoundException($"Key '{key}' not found");

            if (!_storage.TryGetValue(key, out var encryptedData))
                throw new KeyNotFoundException($"Data for key '{key}' not found");

            // Decrypt data
            var decryptedData = DecryptData(encryptedData, encryptionKey);

            // Decompress if needed
            var originalData = metadata.Compression.HasValue 
                ? DecompressData(decryptedData) 
                : decryptedData;

            // Verify hash
            var computedHash = Convert.ToHexString(SHA256.HashData(originalData)).ToLowerInvariant();
            if (computedHash != metadata.Hash)
                throw new InvalidDataException($"Data integrity check failed for key '{key}'");

            // Update access metadata
            metadata.AccessedAt = DateTimeOffset.UtcNow.ToUnixTimeSeconds();
            metadata.AccessCount++;

            return await Task.FromResult(originalData);
        }

        public async Task<string> DeleteDataAsync(string key)
        {
            if (string.IsNullOrEmpty(key))
                throw new ArgumentException("Storage key cannot be empty");

            if (!_metadata.ContainsKey(key))
                throw new KeyNotFoundException($"Key '{key}' not found");

            _metadata.Remove(key);
            _storage.Remove(key);

            // Remove from disk
            await DeleteFromDiskAsync(key);

            var result = new
            {
                deleted = true,
                key = key,
                timestamp = DateTimeOffset.UtcNow.ToUnixTimeSeconds()
            };

            return JsonSerializer.Serialize(result);
        }

        public async Task<string> GetMetadataAsync(string key)
        {
            if (!_metadata.TryGetValue(key, out var metadata))
                throw new KeyNotFoundException($"Key '{key}' not found");

            return await Task.FromResult(JsonSerializer.Serialize(metadata));
        }

        public async Task<string> ListKeysAsync()
        {
            var result = new
            {
                keys = _metadata.Keys.ToArray(),
                count = _metadata.Count,
                timestamp = DateTimeOffset.UtcNow.ToUnixTimeSeconds()
            };

            return await Task.FromResult(JsonSerializer.Serialize(result));
        }

        public async Task<string> GetUsageStatsAsync()
        {
            var totalSize = _metadata.Values.Sum(m => (long)m.Size);
            var totalCompressedSize = _metadata.Values.Sum(m => (long)(m.CompressedSize ?? m.Size));
            var compressionRatio = totalSize > 0 ? (double)totalCompressedSize / totalSize : 1.0;

            var stats = new StorageStats
            {
                TotalFiles = _metadata.Count,
                TotalSize = (ulong)totalSize,
                TotalCompressedSize = (ulong)totalCompressedSize,
                CompressionRatio = compressionRatio,
                AvailableSpace = 10UL * 1024 * 1024 * 1024, // 10GB simulated
                UsedSpace = (ulong)totalCompressedSize
            };

            return await Task.FromResult(JsonSerializer.Serialize(stats));
        }

        public async Task<string> OptimizeStorageAsync()
        {
            var startTime = System.Diagnostics.Stopwatch.StartNew();
            
            // Simulate optimization work
            await Task.Delay(100);
            
            var results = new StorageOptimizationResults
            {
                FilesProcessed = (uint)_metadata.Count,
                BytesReclaimed = 0,
                FragmentationReduced = 0.0,
                CompressionImproved = 0,
                FilesArchived = 0,
                OptimizationTimeMs = (ulong)startTime.ElapsedMilliseconds
            };

            return JsonSerializer.Serialize(results);
        }

        private byte[] CompressData(byte[] data)
        {
            {
                gzip.Write(data, 0, data.Length);
            }
            return output.ToArray();
        }

        private byte[] DecompressData(byte[] compressedData)
        {
            gzip.CopyTo(output);
            return output.ToArray();
        }

        private byte[] EncryptData(byte[] data, string userKey)
        {
            // Derive encryption key
            var derivedKey = DeriveKey(userKey);
            
            var nonce = new byte[12];
            RandomNumberGenerator.Fill(nonce);
            
            var ciphertext = new byte[data.Length];
            var tag = new byte[16];
            
            aes.Encrypt(nonce, data, ciphertext, tag);
            
            // Combine nonce + ciphertext + tag
            var result = new byte[12 + data.Length + 16];
            nonce.CopyTo(result, 0);
            ciphertext.CopyTo(result, 12);
            tag.CopyTo(result, 12 + data.Length);
            
            return result;
        }

        private byte[] DecryptData(byte[] encryptedData, string userKey)
        {
            if (encryptedData.Length < 28)
                throw new CryptographicException("Encrypted data too short");

            var derivedKey = DeriveKey(userKey);
            
            
            var nonce = encryptedData[0..12];
            var ciphertext = encryptedData[12..^16];
            var tag = encryptedData[^16..];
            
            var plaintext = new byte[ciphertext.Length];
            
            try
            {
                aes.Decrypt(nonce, ciphertext, tag, plaintext);
            }
            catch (CryptographicException)
            {
                throw new CryptographicException("Decryption failed - invalid key or tampered data");
            }
            
            return plaintext;
        }

        private byte[] DeriveKey(string userKey)
        {
                Encoding.UTF8.GetBytes(userKey),
                _masterKey,
                100000,
                HashAlgorithmName.SHA256
            );
            return pbkdf2.GetBytes(32);
        }

        private async Task WriteToDiskAsync(string key, byte[] data)
        {
            var hash = SHA256.HashData(Encoding.UTF8.GetBytes(key));
            var filename = Convert.ToHexString(hash).ToLowerInvariant() + ".dat";
            var filepath = Path.Combine(_config.storage_path, filename);
            await File.WriteAllBytesAsync(filepath, data);
        }

        private async Task DeleteFromDiskAsync(string key)
        {
            var hash = SHA256.HashData(Encoding.UTF8.GetBytes(key));
            var filename = Convert.ToHexString(hash).ToLowerInvariant() + ".dat";
            var filepath = Path.Combine(_config.storage_path, filename);
            if (File.Exists(filepath))
            {
                File.Delete(filepath);
            }
            await Task.CompletedTask;
        }

        public void Dispose()
        {
            _metadata.Clear();
            _storage.Clear();
        }
    }

    // Supporting types for the tests
    public enum CompressionType
    {
        Gzip,
        Lz4
    }

    public class StorageMetadata
    {
        public string Key { get; set; }
        public long Size { get; set; }
        public long? CompressedSize { get; set; }
        public long CreatedAt { get; set; }
        public long AccessedAt { get; set; }
        public long ModifiedAt { get; set; }
        public CompressionType? Compression { get; set; }
        public bool Encryption { get; set; }
        public string Hash { get; set; }
        public long AccessCount { get; set; }
    }

    public class StorageStats
    {
        public int TotalFiles { get; set; }
        public ulong TotalSize { get; set; }
        public ulong TotalCompressedSize { get; set; }
        public double CompressionRatio { get; set; }
        public ulong AvailableSpace { get; set; }
        public ulong UsedSpace { get; set; }
    }

    public class StorageOptimizationResults
    {
        public uint FilesProcessed { get; set; }
        public ulong BytesReclaimed { get; set; }
        public double FragmentationReduced { get; set; }
        public uint CompressionImproved { get; set; }
        public uint FilesArchived { get; set; }
        public ulong OptimizationTimeMs { get; set; }
    }
}