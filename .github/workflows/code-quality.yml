name: 🔍 Code Quality & Standards Enforcement

on:
  push:
    branches: [ main, master, develop ]
    paths:
      - 'src/**'
      - 'tests/**'
      - '*.sln'
      - '**/*.csproj'
      - '.github/workflows/code-quality.yml'
  pull_request:
    branches: [ main, master ]
    paths:
      - 'src/**'
      - 'tests/**'
      - '*.sln'
      - '**/*.csproj'
  workflow_dispatch:
    inputs:
      run_full_analysis:
        description: 'Run full analysis including expensive checks'
        required: false
        default: false
        type: boolean

env:
  DOTNET_VERSION: '9.0.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  MIN_CODE_COVERAGE: 75
  MIN_BRANCH_COVERAGE: 70
  SONAR_PROJECT_KEY: 'neo-service-layer'
  SONAR_ORGANIZATION: 'neo-project'

permissions:
  contents: read
  security-events: write
  pull-requests: write
  issues: write
  checks: write
  statuses: write

jobs:
  # 🔍 Code Quality Analysis Matrix
  code-analysis:
    name: 🔍 Code Analysis (${{ matrix.analysis }})
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        analysis: [coverage, security, style, complexity]
        include:
          - analysis: coverage
            name: "Coverage Analysis"
            run_tests: true
            generate_reports: true
          - analysis: security
            name: "Security Analysis"
            run_tests: false
            generate_reports: false
          - analysis: style
            name: "Code Style & Format"
            run_tests: false
            generate_reports: false
          - analysis: complexity
            name: "Code Complexity"
            run_tests: false
            generate_reports: false
    
    outputs:
      coverage-passed: ${{ steps.coverage-result.outputs.passed }}
      security-passed: ${{ steps.security-result.outputs.passed }}
      style-passed: ${{ steps.style-result.outputs.passed }}
      complexity-passed: ${{ steps.complexity-result.outputs.passed }}
    
    steps:
    - name: 📥 Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: 🔧 Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}

    - name: 🚀 Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.nuget/packages
          ~/.dotnet/tools
        key: ${{ runner.os }}-dotnet-quality-${{ hashFiles('**/*.csproj', 'global.json') }}
        restore-keys: |
          ${{ runner.os }}-dotnet-quality-
          ${{ runner.os }}-dotnet-

    - name: 📦 Restore dependencies
      run: |
        echo "::group::Restoring dependencies"
        dotnet restore --verbosity minimal
        echo "::endgroup::"

    - name: 🏗️ Build solution
      run: |
        echo "::group::Building solution"
        dotnet build --configuration Release --no-restore --verbosity minimal
        echo "::endgroup::"

    # Coverage Analysis
    - name: 🧪 Run tests with coverage
      if: ${{ matrix.analysis == 'coverage' }}
      run: |
        echo "::group::Running tests with coverage collection"
        dotnet test \
          --configuration Release \
          --no-build \
          --verbosity minimal \
          --logger trx \
          --results-directory TestResults/ \
          --collect:"XPlat Code Coverage" \
          --settings tests/codecoverage.runsettings \
          --filter "Category!=Integration&Category!=Performance" \
          -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=cobertura
        echo "::endgroup::"

    - name: 📊 Generate coverage report
      if: ${{ matrix.analysis == 'coverage' }}
      uses: danielpalme/ReportGenerator-GitHub-Action@5.2.0
      with:
        reports: 'TestResults/**/coverage.cobertura.xml'
        targetdir: 'TestResults/CoverageReport'
        reporttypes: 'HtmlInline_AzurePipelines;Cobertura;JsonSummary;Badges;MarkdownSummary'
        verbosity: 'Warning'

    - name: 📈 Analyze coverage results
      id: coverage-result
      if: ${{ matrix.analysis == 'coverage' }}
      run: |
        echo "::group::Analyzing coverage results"
        if [ -f "TestResults/CoverageReport/Summary.json" ]; then
          COVERAGE=$(cat TestResults/CoverageReport/Summary.json | jq -r '.coverage.linecoverage // 0')
          BRANCH_COVERAGE=$(cat TestResults/CoverageReport/Summary.json | jq -r '.coverage.branchcoverage // 0')
          
          echo "📊 Coverage Results:"
          echo "  Line Coverage: ${COVERAGE}%"
          echo "  Branch Coverage: ${BRANCH_COVERAGE}%"
          echo "  Required Line Coverage: ${MIN_CODE_COVERAGE}%"
          echo "  Required Branch Coverage: ${MIN_BRANCH_COVERAGE}%"
          
          echo "line-coverage=${COVERAGE}" >> $GITHUB_OUTPUT
          echo "branch-coverage=${BRANCH_COVERAGE}" >> $GITHUB_OUTPUT
          
          # Check if thresholds are met
          if (( $(echo "${COVERAGE} >= ${MIN_CODE_COVERAGE}" | bc -l) )) && (( $(echo "${BRANCH_COVERAGE} >= ${MIN_BRANCH_COVERAGE}" | bc -l) )); then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "✅ Coverage thresholds met"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "❌ Coverage thresholds not met"
            echo "::error::Code coverage below threshold - Line: ${COVERAGE}% (required: ${MIN_CODE_COVERAGE}%), Branch: ${BRANCH_COVERAGE}% (required: ${MIN_BRANCH_COVERAGE}%)"
          fi
        else
          echo "passed=false" >> $GITHUB_OUTPUT
          echo "::error::No coverage report generated"
        fi
        echo "::endgroup::"

    # Security Analysis
    - name: 🔒 Security vulnerability scan
      id: security-result
      if: ${{ matrix.analysis == 'security' }}
      run: |
        echo "::group::Security Analysis"
        SECURITY_PASSED=true
        
        # Check for vulnerable NuGet packages
        echo "🔍 Checking for vulnerable NuGet packages..."
        if dotnet list package --vulnerable --include-transitive 2>&1 | grep -q "has the following vulnerable packages"; then
          echo "❌ Vulnerable packages detected:"
          dotnet list package --vulnerable --include-transitive
          SECURITY_PASSED=false
        else
          echo "✅ No vulnerable packages detected"
        fi
        
        # Basic secret scanning
        echo "🔍 Scanning for potential secrets..."
        SECRET_PATTERNS=(
          "password\s*[=:]\s*['\"][^'\"]{8,}['\"]"
          "api[_-]?key\s*[=:]\s*['\"][^'\"]{16,}['\"]"
          "secret\s*[=:]\s*['\"][^'\"]{16,}['\"]"
          "token\s*[=:]\s*['\"][^'\"]{16,}['\"]"
          "private[_-]?key\s*[=:]\s*['\"][^'\"]{32,}['\"]"
        )
        
        for pattern in "${SECRET_PATTERNS[@]}"; do
          if grep -r -E -i "$pattern" src/ --include="*.cs" --include="*.json" --exclude-dir=bin --exclude-dir=obj; then
            echo "⚠️ Potential secret pattern found"
            SECURITY_PASSED=false
          fi
        done
        
        if [ "$SECURITY_PASSED" = true ]; then
          echo "passed=true" >> $GITHUB_OUTPUT
          echo "✅ Security scan completed successfully"
        else
          echo "passed=false" >> $GITHUB_OUTPUT
          echo "❌ Security issues detected"
        fi
        echo "::endgroup::"

    # Code Style Analysis
    - name: 🎨 Code style analysis
      id: style-result
      if: ${{ matrix.analysis == 'style' }}
      run: |
        echo "::group::Code Style Analysis"
        STYLE_PASSED=true
        
        # Install dotnet format if not available
        dotnet tool install -g dotnet-format --version 5.1.250801 2>/dev/null || true
        
        # Check code formatting
        echo "🎨 Checking code formatting..."
        if ! dotnet format --verify-no-changes --verbosity minimal; then
          echo "❌ Code formatting issues detected"
          echo "::error::Code is not properly formatted. Run 'dotnet format' to fix."
          STYLE_PASSED=false
        else
          echo "✅ Code formatting is correct"
        fi
        
        # Check for code style violations
        echo "🔍 Checking for style violations..."
        if dotnet build --configuration Release --verbosity normal 2>&1 | grep -E "(warning CS|error CS)" | grep -v "CS0618"; then
          echo "❌ Code style warnings detected"
          STYLE_PASSED=false
        else
          echo "✅ No style violations found"
        fi
        
        if [ "$STYLE_PASSED" = true ]; then
          echo "passed=true" >> $GITHUB_OUTPUT
          echo "✅ Code style analysis passed"
        else
          echo "passed=false" >> $GITHUB_OUTPUT
          echo "❌ Code style issues detected"
        fi
        echo "::endgroup::"

    # Code Complexity Analysis
    - name: 📊 Code complexity analysis
      id: complexity-result
      if: ${{ matrix.analysis == 'complexity' || github.event.inputs.run_full_analysis == 'true' }}
      run: |
        echo "::group::Code Complexity Analysis"
        COMPLEXITY_PASSED=true
        
        # Install code metrics tool
        dotnet tool install -g dotnet-code-metrics --version 1.0.0 2>/dev/null || echo "Code metrics tool not available"
        
        # Basic complexity checks using built-in analyzers
        echo "📊 Analyzing code complexity..."
        if dotnet build --configuration Release --verbosity normal 2>&1 | grep -E "CA1502|CA1505|CA1506"; then
          echo "⚠️ High complexity warnings detected"
          # Don't fail on complexity warnings, just report
        fi
        
        echo "passed=true" >> $GITHUB_OUTPUT
        echo "✅ Code complexity analysis completed"
        echo "::endgroup::"

    - name: 📤 Upload coverage artifacts
      uses: actions/upload-artifact@v4
      if: ${{ matrix.analysis == 'coverage' && always() }}
      with:
        name: coverage-report-${{ github.run_number }}
        path: TestResults/CoverageReport/
        retention-days: 30

  # 🎯 Quality Gate Enforcement
  quality-gate-enforcement:
    name: 🎯 Quality Gate Enforcement
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [code-analysis]
    if: always()
    
    steps:
    - name: 📊 Evaluate quality gates
      id: evaluation
      run: |
        echo "::group::Quality Gate Evaluation"
        
        # Get results from analysis jobs
        COVERAGE_PASSED="${{ needs.code-analysis.outputs.coverage-passed }}"
        SECURITY_PASSED="${{ needs.code-analysis.outputs.security-passed }}"
        STYLE_PASSED="${{ needs.code-analysis.outputs.style-passed }}"
        COMPLEXITY_PASSED="${{ needs.code-analysis.outputs.complexity-passed }}"
        
        echo "📋 Quality Gate Results:"
        echo "  Coverage Analysis: ${COVERAGE_PASSED:-N/A}"
        echo "  Security Analysis: ${SECURITY_PASSED:-N/A}"
        echo "  Style Analysis: ${STYLE_PASSED:-N/A}"
        echo "  Complexity Analysis: ${COMPLEXITY_PASSED:-N/A}"
        
        # Determine overall status
        FAILED_GATES=()
        
        if [ "$COVERAGE_PASSED" != "true" ]; then
          FAILED_GATES+=("Coverage")
        fi
        
        if [ "$SECURITY_PASSED" != "true" ]; then
          FAILED_GATES+=("Security")
        fi
        
        if [ "$STYLE_PASSED" != "true" ]; then
          FAILED_GATES+=("Style")
        fi
        
        # Complexity is not blocking by default
        
        if [ ${#FAILED_GATES[@]} -eq 0 ]; then
          echo "overall-status=success" >> $GITHUB_OUTPUT
          echo "✅ All quality gates passed!"
          echo "QUALITY_STATUS=✅ All quality gates passed" >> $GITHUB_ENV
        else
          echo "overall-status=failure" >> $GITHUB_OUTPUT
          echo "❌ Quality gates failed: ${FAILED_GATES[*]}"
          echo "QUALITY_STATUS=❌ Failed: ${FAILED_GATES[*]}" >> $GITHUB_ENV
          echo "::error::Quality gates failed: ${FAILED_GATES[*]}"
        fi
        
        echo "failed-gates=${FAILED_GATES[*]}" >> $GITHUB_OUTPUT
        echo "::endgroup::"

    - name: 📈 Generate quality summary
      run: |
        echo "# 🎯 Code Quality Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## 📊 Quality Gate Results" >> $GITHUB_STEP_SUMMARY
        echo "| Gate | Status | Details |" >> $GITHUB_STEP_SUMMARY
        echo "|------|--------|---------|" >> $GITHUB_STEP_SUMMARY
        echo "| 📊 Coverage | ${{ needs.code-analysis.outputs.coverage-passed == 'true' && '✅ Passed' || '❌ Failed' }} | Min: ${MIN_CODE_COVERAGE}% line, ${MIN_BRANCH_COVERAGE}% branch |" >> $GITHUB_STEP_SUMMARY
        echo "| 🔒 Security | ${{ needs.code-analysis.outputs.security-passed == 'true' && '✅ Passed' || '❌ Failed' }} | Vulnerability and secret scanning |" >> $GITHUB_STEP_SUMMARY
        echo "| 🎨 Style | ${{ needs.code-analysis.outputs.style-passed == 'true' && '✅ Passed' || '❌ Failed' }} | Code formatting and style rules |" >> $GITHUB_STEP_SUMMARY
        echo "| 📈 Complexity | ${{ needs.code-analysis.outputs.complexity-passed == 'true' && '✅ Passed' || '⚠️ Warning' }} | Code complexity analysis |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Overall Status:** ${{ env.QUALITY_STATUS }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## 🔗 Resources" >> $GITHUB_STEP_SUMMARY
        echo "- [Coverage Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)" >> $GITHUB_STEP_SUMMARY
        echo "- [Security Dashboard](https://github.com/${{ github.repository }}/security)" >> $GITHUB_STEP_SUMMARY
        echo "- [Code Quality Guidelines](https://github.com/${{ github.repository }}/blob/main/docs/CONTRIBUTING.md)" >> $GITHUB_STEP_SUMMARY

    - name: 💬 Comment on PR
      uses: actions/github-script@v7
      if: ${{ github.event_name == 'pull_request' }}
      with:
        script: |
          const coveragePassed = '${{ needs.code-analysis.outputs.coverage-passed }}' === 'true';
          const securityPassed = '${{ needs.code-analysis.outputs.security-passed }}' === 'true';
          const stylePassed = '${{ needs.code-analysis.outputs.style-passed }}' === 'true';
          const overallStatus = '${{ steps.evaluation.outputs.overall-status }}';
          
          const statusIcon = overallStatus === 'success' ? '✅' : '❌';
          const statusText = overallStatus === 'success' ? 'All quality gates passed!' : 'Some quality gates failed';
          
          const comment = `## ${statusIcon} Code Quality Report
          
          ### Quality Gate Results
          | Gate | Status | 
          |------|--------|
          | 📊 Coverage | ${coveragePassed ? '✅ Passed' : '❌ Failed'} |
          | 🔒 Security | ${securityPassed ? '✅ Passed' : '❌ Failed'} |
          | 🎨 Style | ${stylePassed ? '✅ Passed' : '❌ Failed'} |
          
          **Overall:** ${statusText}
          
          ${overallStatus === 'failure' ? '⚠️ Please fix the failing quality gates before merging.' : '🎉 Great job maintaining code quality!'}
          
          ---
          <sub>Generated by [Neo Service Layer Quality Gates](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})</sub>`;
          
          // Find existing comment
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });
          
          const existingComment = comments.find(c => 
            c.user.login === 'github-actions[bot]' && 
            c.body.includes('Code Quality Report')
          );
          
          if (existingComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: existingComment.id,
              body: comment
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });
          }

    - name: ❌ Fail on quality gate violations
      if: ${{ steps.evaluation.outputs.overall-status == 'failure' }}
      run: |
        echo "❌ Quality gates failed: ${{ steps.evaluation.outputs.failed-gates }}"
        echo "Please fix the issues and run the workflow again."
        exit 1