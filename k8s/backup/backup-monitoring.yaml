# ServiceMonitor for Prometheus to scrape backup metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: backup-metrics
  namespace: neo-service-layer
  labels:
    app: backup-monitoring
spec:
  selector:
    matchLabels:
      app: backup-exporter
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

---
# Backup Metrics Exporter Service
apiVersion: v1
kind: Service
metadata:
  name: backup-exporter
  namespace: neo-service-layer
  labels:
    app: backup-exporter
spec:
  ports:
  - name: metrics
    port: 8080
    targetPort: 8080
  selector:
    app: backup-exporter

---
# Backup Metrics Exporter Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backup-exporter
  namespace: neo-service-layer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: backup-exporter
  template:
    metadata:
      labels:
        app: backup-exporter
    spec:
      containers:
      - name: backup-exporter
        image: python:3.11-alpine
        ports:
        - containerPort: 8080
        env:
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: backup-s3-credentials
              key: access-key
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: backup-s3-credentials
              key: secret-key
        - name: BACKUP_BUCKET
          value: "neo-service-layer-backups"
        command:
        - /bin/sh
        - -c
        - |
          cat > /tmp/backup_exporter.py << 'EOF'
          #!/usr/bin/env python3
          import boto3
          import json
          import time
          from datetime import datetime, timedelta
          from http.server import HTTPServer, BaseHTTPRequestHandler
          import os
          
          class BackupMetricsHandler(BaseHTTPRequestHandler):
              def do_GET(self):
                  if self.path == '/metrics':
                      self.send_response(200)
                      self.send_header('Content-type', 'text/plain')
                      self.end_headers()
                      
                      metrics = self.get_backup_metrics()
                      self.wfile.write(metrics.encode())
                  elif self.path == '/health':
                      self.send_response(200)
                      self.send_header('Content-type', 'text/plain')
                      self.end_headers()
                      self.wfile.write(b'OK')
                  else:
                      self.send_response(404)
                      self.end_headers()
              
              def get_backup_metrics(self):
                  s3 = boto3.client('s3')
                  bucket = os.environ.get('BACKUP_BUCKET', 'neo-service-layer-backups')
                  
                  metrics = []
                  
                  # Get backup counts and sizes
                  prefixes = ['postgres/sql/', 'mongodb/', 'redis/', 'configs/']
                  
                  for prefix in prefixes:
                      try:
                          response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
                          
                          if 'Contents' in response:
                              objects = response['Contents']
                              
                              # Count total backups
                              backup_count = len(objects)
                              metrics.append(f'backup_total_count{{type="{prefix.rstrip("/").split("/")[-1]}"}} {backup_count}')
                              
                              # Calculate total size
                              total_size = sum(obj['Size'] for obj in objects)
                              metrics.append(f'backup_total_size_bytes{{type="{prefix.rstrip("/").split("/")[-1]}"}} {total_size}')
                              
                              # Get latest backup info
                              if objects:
                                  latest = max(objects, key=lambda x: x['LastModified'])
                                  age_hours = (datetime.now(latest['LastModified'].tzinfo) - latest['LastModified']).total_seconds() / 3600
                                  metrics.append(f'backup_age_hours{{type="{prefix.rstrip("/").split("/")[-1]}"}} {age_hours:.2f}')
                                  
                                  # Backup success (1 if backup exists within 25 hours)
                                  success = 1 if age_hours < 25 else 0
                                  metrics.append(f'backup_success{{type="{prefix.rstrip("/").split("/")[-1]}"}} {success}')
                          else:
                              # No backups found
                              backup_type = prefix.rstrip('/').split('/')[-1]
                              metrics.append(f'backup_total_count{{type="{backup_type}"}} 0')
                              metrics.append(f'backup_success{{type="{backup_type}"}} 0')
                              
                      except Exception as e:
                          print(f"Error getting metrics for {prefix}: {e}")
                  
                  # Add timestamp
                  metrics.append(f'backup_metrics_last_updated {int(time.time())}')
                  
                  return '\n'.join(metrics) + '\n'
          
          if __name__ == '__main__':
              # Install dependencies
              import subprocess
              subprocess.run(['pip', 'install', 'boto3'], check=True)
              
              server = HTTPServer(('0.0.0.0', 8080), BackupMetricsHandler)
              print("Backup metrics exporter listening on port 8080")
              server.serve_forever()
          EOF
          
          python3 /tmp/backup_exporter.py
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10

---
# PrometheusRule for backup alerting
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: backup-alerts
  namespace: neo-service-layer
  labels:
    app: backup-monitoring
spec:
  groups:
  - name: backup.rules
    rules:
    - alert: BackupFailed
      expr: backup_success == 0
      for: 1h
      labels:
        severity: critical
      annotations:
        summary: "Backup failed for {{ $labels.type }}"
        description: "Backup for {{ $labels.type }} has failed or is missing for more than 25 hours."
    
    - alert: BackupOld
      expr: backup_age_hours > 48
      for: 0m
      labels:
        severity: warning
      annotations:
        summary: "Backup is getting old for {{ $labels.type }}"
        description: "Last backup for {{ $labels.type }} was {{ $value }} hours ago."
    
    - alert: BackupSizeAnomaly
      expr: |
        (
          backup_total_size_bytes > (
            avg_over_time(backup_total_size_bytes[7d]) * 1.5
          )
        ) or (
          backup_total_size_bytes < (
            avg_over_time(backup_total_size_bytes[7d]) * 0.5
          )
        )
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "Backup size anomaly detected for {{ $labels.type }}"
        description: "Backup size for {{ $labels.type }} is significantly different from the 7-day average."
    
    - alert: BackupJobFailed
      expr: kube_job_status_failed{job_name=~"postgres-backup.*|mongodb-backup.*|redis-backup.*|config-backup.*"} > 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Backup job {{ $labels.job_name }} failed"
        description: "Kubernetes backup job {{ $labels.job_name }} has failed."
    
    - alert: BackupPVCSpaceRunningOut
      expr: |
        (
          kubelet_volume_stats_available_bytes{persistentvolumeclaim=~".*backup.*"}
          / kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~".*backup.*"}
        ) < 0.1
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "Backup PVC running out of space"
        description: "Backup PVC {{ $labels.persistentvolumeclaim }} has less than 10% free space remaining."